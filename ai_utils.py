#!/usr/bin/env python3
"""
Utilidades espec√≠ficas para manejo de IA en el Dashboard IT
Cl√≠nica Bonsana
"""

import os
import sys
import json
import time
import argparse
from pathlib import Path
from datetime import datetime
import tempfile
import subprocess
from dotenv import load_dotenv

class AIUtils:
    """Utilidades para manejo de la funcionalidad IA"""
    
    def __init__(self):
        self.project_root = Path(__file__).parent
        load_dotenv()
        self.api_key = os.getenv('GOOGLE_AI_API_KEY')
        self.model_name = os.getenv('GOOGLE_AI_MODEL', 'gemini-1.5-pro')
        
    def check_ai_status(self):
        """Verifica el estado completo del sistema de IA"""
        print("ü§ñ ESTADO DEL SISTEMA DE IA")
        print("=" * 50)
        
        status = {
            'api_key_configured': bool(self.api_key),
            'api_key_valid': False,
            'service_available': False,
            'model_accessible': False,
            'dependencies_installed': False,
            'config_valid': False
        }
        
        # Verificar dependencias
        try:
            import google.generativeai as genai
            status['dependencies_installed'] = True
            print("‚úÖ Dependencias instaladas")
        except ImportError:
            print("‚ùå google-generativeai no instalado")
            return status
        
        # Verificar API key
        if not self.api_key:
            print("‚ùå GOOGLE_AI_API_KEY no configurada")
            return status
        
        if self.api_key in ['tu-api-key-aqui', 'your-api-key-here']:
            print("‚ùå GOOGLE_AI_API_KEY es un placeholder")
            return status
        
        print("‚úÖ API Key configurada")
        
        # Probar conexi√≥n
        try:
            genai.configure(api_key=self.api_key)
            models = list(genai.list_models())
            
            if models:
                status['api_key_valid'] = True
                status['service_available'] = True
                print(f"‚úÖ Conexi√≥n exitosa ({len(models)} modelos disponibles)")
                
                # Verificar modelo espec√≠fico
                model_names = [m.name.split('/')[-1] for m in models]
                if self.model_name in model_names:
                    status['model_accessible'] = True
                    print(f"‚úÖ Modelo {self.model_name} accesible")
                else:
                    print(f"‚ö†Ô∏è  Modelo {self.model_name} no encontrado")
                    print(f"   Modelos disponibles: {', '.join(model_names[:5])}")
            else:
                print("‚ùå No se pudieron obtener modelos")
                
        except Exception as e:
            print(f"‚ùå Error de conexi√≥n: {e}")
            return status
        
        # Verificar configuraci√≥n de la aplicaci√≥n
        try:
            sys.path.insert(0, str(self.project_root))
            from config import get_config
            config = get_config()
            
            if config.AI_ANALYSIS_ENABLED:
                status['config_valid'] = True
                print("‚úÖ Configuraci√≥n de aplicaci√≥n v√°lida")
            else:
                print("‚ö†Ô∏è  IA deshabilitada en configuraci√≥n de aplicaci√≥n")
                
        except Exception as e:
            print(f"‚ùå Error en configuraci√≥n: {e}")
        
        return status
    
    def test_analysis(self, sample_size='small'):
        """Prueba el an√°lisis de IA con datos de ejemplo"""
        print(f"\nüß™ PRUEBA DE AN√ÅLISIS IA ({sample_size.upper()})")
        print("=" * 50)
        
        if not self.api_key:
            print("‚ùå API Key no configurada")
            return False
        
        # Crear CSV de prueba
        test_csv = self.create_test_csv(sample_size)
        
        try:
            sys.path.insert(0, str(self.project_root))
            from app import AIAnalysisService
            
            service = AIAnalysisService()
            
            if not service.is_available():
                print("‚ùå Servicio de IA no disponible")
                return False
            
            print("üîÑ Iniciando an√°lisis...")
            start_time = time.time()
            
            result = service.analyze_tickets(test_csv)
            
            end_time = time.time()
            duration = end_time - start_time
            
            if result['success']:
                print(f"‚úÖ An√°lisis completado en {duration:.1f} segundos")
                print(f"üìä Filas analizadas: {result.get('csv_rows_analyzed', 'N/A')}")
                print(f"üß† Modelo usado: {result.get('model_used', 'N/A')}")
                
                # Mostrar muestra del an√°lisis
                analysis = result['analysis']
                preview_length = 300
                if len(analysis) > preview_length:
                    preview = analysis[:preview_length] + "..."
                else:
                    preview = analysis
                
                print(f"üìù Vista previa del an√°lisis:")
                print("-" * 40)
                print(preview)
                print("-" * 40)
                
                # Guardar an√°lisis completo
                output_file = self.project_root / f'test_analysis_{datetime.now().strftime("%Y%m%d_%H%M%S")}.txt'
                with open(output_file, 'w', encoding='utf-8') as f:
                    f.write(f"An√°lisis de prueba - {datetime.now()}\n")
                    f.write("=" * 50 + "\n\n")
                    f.write(analysis)
                
                print(f"üíæ An√°lisis completo guardado en: {output_file}")
                return True
                
            else:
                print(f"‚ùå Error en an√°lisis: {result.get('error', 'Error desconocido')}")
                return False
                
        except Exception as e:
            print(f"‚ùå Error ejecutando prueba: {e}")
            return False
            
        finally:
            # Limpiar archivo de prueba
            if os.path.exists(test_csv):
                os.remove(test_csv)
    
    def create_test_csv(self, size='small'):
        """Crea CSV de prueba para testing"""
        if size == 'small':
            data_rows = 5
        elif size == 'medium':
            data_rows = 25
        elif size == 'large':
            data_rows = 100
        else:
            data_rows = 5
        
        header = "ID;T√≠tulo;Tipo;Categor√≠a;Prioridad;Estado;Fecha de Apertura;Fecha de soluci√≥n;Se super√≥ el tiempo de resoluci√≥n;Asignado a: - T√©cnico;Solicitante - Solicitante;Elementos asociados;ANS (Acuerdo de nivel de servicio) - ANS (Acuerdo de nivel de servicio) Tiempo de soluci√≥n;Encuesta de satisfacci√≥n - Satisfacci√≥n"
        
        sample_data = [
            "1;Falla impresora consultorio 1;Incidencia;Hardware > Impresora;Alta;Resueltas;2025-05-01 09:00;2025-05-01 11:30;No;Juan P√©rez;Dr. Garc√≠a;IMP-001;INC_ALTO;5",
            "2;Instalaci√≥n software m√©dico;Requerimiento;Software > Aplicaci√≥n;Mediana;Cerrado;2025-05-02 14:00;2025-05-03 10:00;Si;Ana L√≥pez;Enfermera Silva;;REQ_MEDIO;4",
            "3;Red lenta en urgencias;Incidencia;Red > Conectividad;Alta;En curso (asignada);2025-05-03 16:00;;No;Carlos Ruiz;Dr. Mart√≠nez;SW-005;INC_ALTO;",
            "4;Actualizaci√≥n sistema HIS;Requerimiento;Software > Sistema;Alta;Resueltas;2025-05-04 08:00;2025-05-04 18:00;No;Juan P√©rez;Administraci√≥n;SRV-MED;REQ_ALTO;5",
            "5;Mantenimiento PCs recepci√≥n;Incidencia;Hardware > Computador;Baja;Cerrado;2025-05-05 13:00;2025-05-05 15:00;No;Ana L√≥pez;Recepci√≥n;PC-003;INC_BAJO;3",
            "6;Error en sistema facturaci√≥n;Incidencia;Software > Sistema;Alta;Resueltas;2025-05-06 10:00;2025-05-06 14:00;No;Carlos Ruiz;Contabilidad;SRV-FACT;INC_ALTO;4",
            "7;Nuevo usuario sistema;Requerimiento;Acceso > Usuario;Baja;Cerrado;2025-05-07 09:00;2025-05-07 09:30;No;Ana L√≥pez;RRHH;USR-001;REQ_BAJO;5",
            "8;Pantalla no enciende quir√≥fano;Incidencia;Hardware > Monitor;Alta;En curso (asignada);2025-05-08 07:00;;No;Juan P√©rez;Dr. Cirujano;MON-QX1;INC_ALTO;",
            "9;Backup autom√°tico fallando;Incidencia;Sistema > Backup;Mediana;Resueltas;2025-05-09 02:00;2025-05-09 08:00;Si;Carlos Ruiz;IT Manager;SRV-BCK;INC_MEDIO;3",
            "10;Capacitaci√≥n nuevo software;Requerimiento;Capacitaci√≥n > Software;Baja;Cerrado;2025-05-10 15:00;2025-05-12 16:00;No;Ana L√≥pez;Enfermer√≠a;TRAIN-01;REQ_BAJO;4"
        ]
        
        # Repetir datos seg√∫n el tama√±o solicitado
        rows_needed = min(data_rows, len(sample_data))
        selected_rows = sample_data[:rows_needed]
        
        # Si necesitamos m√°s filas, generar datos adicionales
        if data_rows > len(sample_data):
            for i in range(len(sample_data), data_rows):
                # Modificar datos existentes
                base_row = sample_data[i % len(sample_data)]
                parts = base_row.split(';')
                parts[0] = str(i + 1)  # Nuevo ID
                parts[1] = f"Ticket generado {i + 1}"  # Nuevo t√≠tulo
                selected_rows.append(';'.join(parts))
        
        # Crear archivo temporal
        fd, temp_path = tempfile.mkstemp(suffix='.csv', text=True)
        with os.fdopen(fd, 'w', encoding='utf-8') as f:
            f.write(header + '\n')
            for row in selected_rows:
                f.write(row + '\n')
        
        print(f"üìù CSV de prueba creado: {data_rows} filas")
        return temp_path
    
    def benchmark_models(self):
        """Compara el rendimiento de diferentes modelos disponibles"""
        print("\n‚ö° BENCHMARK DE MODELOS")
        print("=" * 50)
        
        if not self.api_key:
            print("‚ùå API Key no configurada")
            return
        
        try:
            import google.generativeai as genai
            genai.configure(api_key=self.api_key)
            
            # Obtener modelos Gemini disponibles
            models = list(genai.list_models())
            gemini_models = [m for m in models if 'gemini' in m.name.lower()]
            
            if not gemini_models:
                print("‚ùå No se encontraron modelos Gemini")
                return
            
            # Crear CSV de prueba peque√±o
            test_csv = self.create_test_csv('small')
            
            # Preparar datos
            with open(test_csv, 'r', encoding='utf-8') as f:
                csv_data = f.read()
            
            simple_prompt = f"Analiza brevemente estos datos de tickets de soporte IT: {csv_data[:500]}..."
            
            results = []
            
            for model in gemini_models[:3]:  # Probar m√°ximo 3 modelos
                model_name = model.name.split('/')[-1]
                print(f"\nüß† Probando modelo: {model_name}")
                
                try:
                    ai_model = genai.GenerativeModel(model_name)
                    
                    start_time = time.time()
                    response = ai_model.generate_content(simple_prompt)
                    end_time = time.time()
                    
                    duration = end_time - start_time
                    response_length = len(response.text) if response.text else 0
                    
                    results.append({
                        'model': model_name,
                        'duration': duration,
                        'response_length': response_length,
                        'success': True
                    })
                    
                    print(f"   ‚úÖ Tiempo: {duration:.2f}s")
                    print(f"   üìè Longitud respuesta: {response_length} caracteres")
                    
                except Exception as e:
                    print(f"   ‚ùå Error: {e}")
                    results.append({
                        'model': model_name,
                        'duration': 0,
                        'response_length': 0,
                        'success': False,
                        'error': str(e)
                    })
            
            # Mostrar resumen
            print(f"\nüìä RESUMEN DEL BENCHMARK")
            print("-" * 40)
            
            successful_results = [r for r in results if r['success']]
            if successful_results:
                fastest = min(successful_results, key=lambda x: x['duration'])
                most_detailed = max(successful_results, key=lambda x: x['response_length'])
                
                print(f"üèÉ M√°s r√°pido: {fastest['model']} ({fastest['duration']:.2f}s)")
                print(f"üìù M√°s detallado: {most_detailed['model']} ({most_detailed['response_length']} chars)")
                
                # Recomendaci√≥n
                if fastest['model'] == most_detailed['model']:
                    print(f"üéØ Recomendado: {fastest['model']} (mejor en ambos aspectos)")
                else:
                    print(f"üéØ Para velocidad: {fastest['model']}")
                    print(f"üéØ Para detalle: {most_detailed['model']}")
            
            # Limpiar
            os.remove(test_csv)
            
        except Exception as e:
            print(f"‚ùå Error en benchmark: {e}")
    
    def estimate_costs(self, csv_path):
        """Estima costos aproximados del an√°lisis IA"""
        print("\nüí∞ ESTIMACI√ìN DE COSTOS")
        print("=" * 30)
        
        if not os.path.exists(csv_path):
            print(f"‚ùå Archivo no encontrado: {csv_path}")
            return
        
        try:
            # Leer archivo y calcular tokens aproximados
            with open(csv_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # Estimaci√≥n rough: ~4 caracteres por token
            estimated_input_tokens = len(content) // 4
            
            # Agregar tokens del prompt base
            sys.path.insert(0, str(self.project_root))
            from config import get_config
            config = get_config()
            prompt_template = config.AI_CONFIG['prompt_template']
            prompt_tokens = len(prompt_template) // 4
            
            total_input_tokens = estimated_input_tokens + prompt_tokens
            
            # Estimar tokens de salida (t√≠picamente 1000-3000 para an√°lisis completo)
            estimated_output_tokens = 2000
            
            # Precios aproximados de Gemini (pueden cambiar)
            # Estos son valores de ejemplo - verificar precios actuales
            price_per_1k_input_tokens = 0.00025  # $0.00025 por 1K tokens input
            price_per_1k_output_tokens = 0.0005   # $0.0005 por 1K tokens output
            
            input_cost = (total_input_tokens / 1000) * price_per_1k_input_tokens
            output_cost = (estimated_output_tokens / 1000) * price_per_1k_output_tokens
            total_cost = input_cost + output_cost
            
            print(f"üìÑ Tama√±o del archivo: {len(content):,} caracteres")
            print(f"üî§ Tokens estimados (input): {total_input_tokens:,}")
            print(f"üî§ Tokens estimados (output): {estimated_output_tokens:,}")
            print(f"üíµ Costo estimado (input): ${input_cost:.4f}")
            print(f"üíµ Costo estimado (output): ${output_cost:.4f}")
            print(f"üí∞ Costo total estimado: ${total_cost:.4f}")
            
            # Estimaciones mensuales
            print(f"\nüìÖ ESTIMACIONES MENSUALES:")
            for frequency, multiplier in [('Diario', 30), ('Semanal', 4), ('Mensual', 1)]:
                monthly_cost = total_cost * multiplier
                print(f"   {frequency}: ${monthly_cost:.2f}/mes")
            
            print(f"\n‚ö†Ô∏è  Nota: Precios aproximados basados en tarifas de ejemplo")
            print(f"   Verificar precios actuales en: https://ai.google.dev/pricing")
            
        except Exception as e:
            print(f"‚ùå Error calculando costos: {e}")
    
    def export_analysis_history(self, output_dir=None):
        """Exporta el historial de an√°lisis realizados"""
        if not output_dir:
            output_dir = self.project_root / 'exports'
        
        output_dir = Path(output_dir)
        output_dir.mkdir(exist_ok=True)
        
        print(f"\nüì¶ EXPORTANDO HISTORIAL")
        print("=" * 30)
        
        # Buscar archivos de an√°lisis
        analysis_files = list(self.project_root.glob('test_analysis_*.txt'))
        
        if not analysis_files:
            print("‚ÑπÔ∏è  No se encontraron archivos de an√°lisis")
            return
        
        export_data = {
            'export_date': datetime.now().isoformat(),
            'total_analyses': len(analysis_files),
            'analyses': []
        }
        
        for file_path in sorted(analysis_files):
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                # Extraer metadatos del archivo
                file_stats = file_path.stat()
                
                analysis_info = {
                    'filename': file_path.name,
                    'creation_date': datetime.fromtimestamp(file_stats.st_ctime).isoformat(),
                    'size_bytes': file_stats.st_size,
                    'content_preview': content[:500] + "..." if len(content) > 500 else content
                }
                
                export_data['analyses'].append(analysis_info)
                
            except Exception as e:
                print(f"‚ö†Ô∏è  Error procesando {file_path.name}: {e}")
        
        # Guardar export
        export_file = output_dir / f'analysis_history_{datetime.now().strftime("%Y%m%d_%H%M%S")}.json'
        
        with open(export_file, 'w', encoding='utf-8') as f:
            json.dump(export_data, f, indent=2, ensure_ascii=False)
        
        print(f"‚úÖ Historial exportado: {export_file}")
        print(f"üìä Total de an√°lisis: {len(analysis_files)}")
    
    def cleanup_temp_files(self):
        """Limpia archivos temporales de an√°lisis"""
        print("\nüßπ LIMPIEZA DE ARCHIVOS TEMPORALES")
        print("=" * 40)
        
        # Archivos de an√°lisis de prueba
        analysis_files = list(self.project_root.glob('test_analysis_*.txt'))
        
        # Archivos CSV temporales
        temp_csv_files = list(self.project_root.glob('temp_*.csv'))
        
        all_temp_files = analysis_files + temp_csv_files
        
        if not all_temp_files:
            print("‚úÖ No hay archivos temporales para limpiar")
            return
        
        for file_path in all_temp_files:
            try:
                file_path.unlink()
                print(f"üóëÔ∏è  Eliminado: {file_path.name}")
            except Exception as e:
                print(f"‚ö†Ô∏è  Error eliminando {file_path.name}: {e}")
        
        print(f"‚úÖ Limpieza completada: {len(all_temp_files)} archivos procesados")

def main():
    """Funci√≥n principal para CLI"""
    parser = argparse.ArgumentParser(description='Utilidades para IA - Dashboard IT Cl√≠nica Bonsana')
    
    subparsers = parser.add_subparsers(dest='command', help='Comandos disponibles')
    
    # Comando para verificar estado
    status_parser = subparsers.add_parser('status', help='Verificar estado del sistema IA')
    
    # Comando para probar an√°lisis
    test_parser = subparsers.add_parser('test', help='Probar an√°lisis con datos de ejemplo')
    test_parser.add_argument('--size', choices=['small', 'medium', 'large'], 
                           default='small', help='Tama√±o del dataset de prueba')
    
    # Comando para benchmark
    benchmark_parser = subparsers.add_parser('benchmark', help='Comparar modelos disponibles')
    
    # Comando para estimar costos
    cost_parser = subparsers.add_parser('cost', help='Estimar costos de an√°lisis')
    cost_parser.add_argument('csv_path', help='Ruta al archivo CSV')
    
    # Comando para exportar historial
    export_parser = subparsers.add_parser('export', help='Exportar historial de an√°lisis')
    export_parser.add_argument('--output', help='Directorio de salida')
    
    # Comando para limpiar
    cleanup_parser = subparsers.add_parser('cleanup', help='Limpiar archivos temporales')
    
    args = parser.parse_args()
    
    if not args.command:
        parser.print_help()
        return
    
    utils = AIUtils()
    
    if args.command == 'status':
        status = utils.check_ai_status()
        
        # C√≥digo de salida basado en el estado
        if all([status['dependencies_installed'], status['api_key_valid'], 
                status['service_available'], status['config_valid']]):
            print("\n‚úÖ Sistema IA completamente funcional")
            sys.exit(0)
        else:
            print("\n‚ö†Ô∏è  Sistema IA tiene problemas")
            sys.exit(1)
            
    elif args.command == 'test':
        success = utils.test_analysis(args.size)
        sys.exit(0 if success else 1)
        
    elif args.command == 'benchmark':
        utils.benchmark_models()
        
    elif args.command == 'cost':
        utils.estimate_costs(args.csv_path)
        
    elif args.command == 'export':
        utils.export_analysis_history(args.output)
        
    elif args.command == 'cleanup':
        utils.cleanup_temp_files()

if __name__ == '__main__':
    main()